# MORSE-500: A Programmatically Controllable Video Benchmark to Stress-Test Multimodal Reasoning  
**Code & Evaluation Suite**

**[Project Website](https://morse-500.github.io/)** Â· **[Hugging Face Dataset](https://huggingface.co/datasets/video-reasoning/morse-500)**â€‚Â·â€‚**[HF Dataset Viewer](https://huggingface.co/datasets/video-reasoning/morse-500-view)**

---

## âœ¨ Key Features

| Aspect | Details |
| --- | --- |
| **Fresh & Portable** | 500 newly cooked video clips + CSV metadata that runs fast |
| **Scalable Difficulty** | Videos are generated programmatically so we can dial up complexity and release harder versions as models improve |
| **Diverse Categories** | *Abstract, Mathematical, Physical, Planning, Spatial, Temporal (+ Causal)* â€“ evenly distributed across reasoning types that actually matter |
| **Pure Visual Reasoning** | Questions are baked right into the videos. No text crutches, no shortcuts â€“ if you can't see it, you can't solve it |
| **Developer-Friendly** | A â€œ[-view](https://huggingface.co/datasets/video-reasoning/morse-500-view)â€ subset streams directly on **Hugging Face** for quick browsing and debugging |

---

## âš¡ Quick Start

```bash
# Clone repo & install dependencies
git clone https://github.com/morse-benchmark/morse-500-code.git
cd morse-500-code
pip install -r requirements.txt        # datasets, moviepy â€¦

cd eval
# 1ï¸âƒ£ Run a baseline model
python eval_model.py

# 2ï¸âƒ£ Extract answers from model output
python extract_answers.py pred_sz512_o3.csv

# 3ï¸âƒ£ Compute benchmark scores / generate table
python plot_table.py
```


## ğŸ“‚ [Dataset](https://huggingface.co/datasets/video-reasoning/morse-500) Format

```
morse-500/
â”œâ”€â”€ test.csv            # metadata, columns: id, video, query, question_text, ground_truth, category
â”œâ”€â”€ test.zip            # videos of original size
â”œâ”€â”€ test_sz512.zip      # videos with long side resized to 512 while keeping original aspect ratio
â”œâ”€â”€ test/               # After unzip, each mp4 file corresponds to "video" column in test.csv
â”‚   â”œâ”€â”€ xxx.mp4
â”‚   â”œâ”€â”€ xxx.mp4
â”‚   â””â”€â”€ â€¦
â””â”€â”€ README.md
```

## ğŸ›ï¸ Repository Layout
```
morse-500-code/
â”œâ”€â”€ eval/                       # evaluate model, extract answers, plot tables
â”‚   â”œâ”€â”€ pred/                   # contains prediction from differet models
â”‚   â”œâ”€â”€ extract/                # contains extraction using Qwen2.5 72B Inst AWQ
â”‚   â”œâ”€â”€ eval_model.py
â”‚   â”œâ”€â”€ extract_answers.py
â”‚   â”œâ”€â”€ plot_table.py
â”‚   â””â”€â”€ run.sh
â”œâ”€â”€ manim-algebraic-reasoning   # code for generating algebraic-reasoning videos using manim library
â””â”€â”€ xxx                         # other code for generating videos of other categories
```



<!-- ## ğŸ“ Citation
If you use MORSE-500 or our evaluation code, please cite:
```

```


## ğŸ“„ License
- Code â€“ MIT
- Dataset (videos + metadata) â€“ CC BY-4.0 (attribution required)  -->
